<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>欧络因の魔法店</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://lixiuyu.cc/"/>
  <updated>2018-01-25T14:37:29.226Z</updated>
  <id>http://lixiuyu.cc/</id>
  
  <author>
    <name>Olórin</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>AP统计中几个知识点的解释</title>
    <link href="http://lixiuyu.cc/2018/01/24/stat/"/>
    <id>http://lixiuyu.cc/2018/01/24/stat/</id>
    <published>2018-01-24T14:11:27.000Z</published>
    <updated>2018-01-25T14:37:29.226Z</updated>
    
    <content type="html"><![CDATA[<p>去年在学习AP <del>TI-84/NSPIRE艺术</del>统计时，总有一些骚操作让人一头雾水。而每当询问Mr. Z时，他也只是会说“This is an AP level course. You only need to know how to press the calculator.” 本篇文章讨论了几个AP统计中涵盖的公式及比较有意思的知识点背后的原理。</p><a id="more"></a><p><em>注：本篇文章大部分专业词汇使用英文，以便于读者将它们与AP统计中所学的概念相对应，若对中英文夹杂感到不适还请见谅</em></p><h2 id="Sample-Variance-Formula"><a href="#Sample-Variance-Formula" class="headerlink" title="Sample Variance Formula"></a>Sample Variance Formula</h2><p>在学习sample variance的时候，我对于其计算公式</p><center>$$ s_x^2=\frac{1}{n-1}\sum{(x_i-\bar{x})^2}$$</center><p>中的$n-1$（而不是$n$）非常不解，而在课本<em>The Basic Practice of Statistics for AP</em> 431页单纯通过举例子计算的解释显然是一点帮助也没有。。。不过其提到的一个词<em>biased estimator</em>却的确是问题的关键：</p><p><strong>当我们有一个参数为实数$\theta$的概率模型，构造关系$u$，若对任意观测数据$X$，都有</strong></p><center>$E[u(X_1,X_2,\ldots,X_n)]=\theta$</center><p><strong>则我们称$u(X_1,X_2,\ldots,X_n)$是一个对$\theta$的<em>unbiased estimator</em>。否则，$u(X_1,X_2,\ldots,X_n)$是一个对$\theta$的<em>biased estimator</em></strong></p><p>对于任意一个服从分布$F$的随机变量$X$，已知$X$的期望为$\mu$，则随机变量$X$或分布$F$的真实方差为</p><center>$Var(X) = \sigma^2=E[(X-\mu)^2]$</center><p>由此可得</p><center>$\displaystyle Var(X)=\sigma^2=E[\frac{1}{n}\sum_{i=1}^{n}(X_i - \mu)^2]$</center><p>这一个$E[\frac{1}{n}\sum_{i=1}^{n}(X_i - \mu)^2]$就是对真实方差的一个<em>unbiased estimator</em>。而在计算sample variance中，当直接以$n$作为分母时，所得出的sample variance却是对$Var(X)$的一个<em>biased estimator</em>，并不是我们真正想要的方差。这是因为我们在计算时并不知道$X$的期望$\mu$，只能用样本均值$\bar{X}$代替（本质原因是样本均值$\bar{X}$是期望$\mu$的<strong>ordinary least squares</strong>，本篇文章不对此进行深入展开）。若以$n$为分母计算sample variance $s_x^{‘2}$，则会有</p>\begin{align} E[s_x^{'2}] &= E[\frac{1}{n}\sum_{i=1}^{n}(X_i - \bar{X})^2]\\\\&= E[\frac{1}{n}\sum_{i=1}^{n}(X_i - \mu + \mu - \bar{X})^2]\\\\&= E[\frac{1}{n}\sum_{i=1}^{n}(X_i - \mu - (\bar{X} - \mu))^2]\\\\&= E[\frac{1}{n}\sum_{i=1}^{n}((X_i - \mu)^2 - 2(X_i - \mu)(\bar{X}-\mu) + (\bar{X}-\mu)^2))]\\\\&= E[\frac{1}{n}(\sum_{i=1}^{n}(X_i - \mu)^2 - 2n(\bar{X} - \mu)(\bar{X}-\mu) + n(\bar{X}-\mu)^2)]\\\\&= E[\frac{1}{n}\sum_{i=1}^{n}(X_i - \mu)^2] - E[\frac{1}{n}*n(\bar{X}-\mu)^2]\\\\&= \frac{1}{n}E[\sum_{i=1}^{n}(X_i - \mu)^2] - \frac{1}{n}*nE[(\bar{X}-\mu)^2]\\\\&= \frac{1}{n}(nVar(X) - nVar(\bar{X}))\\\\&= Var(X) - Var(\bar{X})\end{align}<p>而sample mean的方差为$\sigma_M^2=\frac{\sigma^2}{n}$（这个公式也可以从课本中的standard deviation of $\bar{X}$中推出）。因此，我们有</p><center>$E[s_x^{‘2}]=\sigma^2-\frac{\sigma^2}{n}=\frac{(n-1)\sigma^2}{n}$</center><p>由此可得，当分母为$n$时，计算出的sample variance是真实方差的<em>biased estimator</em>，而将分母变回$n-1$时，$s_x^2$的期望则是</p><center>$E[s_x^2]=\frac{1}{n-1}(nVar(X) - nVar(\bar{X}))=\frac{n}{n-1}\frac{(n-1)\sigma^2}{n}=\sigma^2$</center><p>所以$ s_x^2=\frac{1}{n-1}\sum{(x_i-\bar{x})^2}$是对sample variance的<em>unbiased estimator</em>。将原来的$biased$的$E[s_x^{‘2}]$变为$unbiased$的$E[s_x^2]$所乘的系数$\frac{n}{n-1}$被称为<strong>Bessel’s correction</strong>。</p><h2 id="Control-of-Type-II-Error"><a href="#Control-of-Type-II-Error" class="headerlink" title="Control of Type II Error"></a>Control of Type II Error</h2><p>做过AP统计significance test这一章选择题的各位都知道，如果想要减小假设检验发生Type II error (when it fails to reject a null hypothesis $H_0$ that really is false)的概率，可以使用增大样本容量（increase sample size）的方法。但书上和统计老师都并未对这样做的原理进行解释。本节将会提供两个对在<em>z test</em>中通过增大样本容量降低Type II error发生概率的解释。</p><h3 id="Explanation-I"><a href="#Explanation-I" class="headerlink" title="Explanation I"></a>Explanation I</h3><p>第一个解释比较直观。举一个简单例子，现在要估算HFI学生在上一次统计考试中的平均成绩，我们的null hypothesis ($H_0$)是平均成绩为$\mu_1$，即上次考试中学生成绩符合正态分布（Normal distribution）$N(\mu_1, \sigma^2)$。而我们的alternative hypothesis ($H_1$)是平均成绩为大于$\mu_1$的某个值，设该值为$\mu_2$，也就是说学生成绩符合正态分布$N(\mu_2, \sigma^2)$。</p><p>当我们随机选取$n$个学生计算他们的平均成绩$\bar{X}$，再通过$z = \frac{\bar{X}-\mu_1}{\sigma/\sqrt{n}}$计算出<em>z score</em>与对应的<em>P-value</em>，即可根据<em>P-value</em>推断学生的平均成绩是$\mu_1$还是$\mu_2$（即接受或拒绝$H_0$）。而由<em>z score</em>的计算公式可以得知，$\bar{X}$的位置决定抽样学生成绩属于正态分布$N(\mu_1, \frac{\sigma^2}{n})$还是$N(\mu_2, \frac{\sigma^2}{n})$。</p><p>因此，若在下图中x轴上$\alpha$ (significance level)对应的<em>z score</em>处有一点$k$，则当$\bar{X}&lt; k$时接受$H_0$，当$\bar{X}&gt;k$时拒绝$H_0$（若相等则增大样本容量重新计算）。</p><p><img src="/2018/01/24/stat/mean.png" alt=""></p><p>这个时候可得Type II error的概率就是$P(N(\mu_2,\frac{\sigma^2}{n})&lt;k)$，即落在k左边的$N(\mu_2, \frac{\sigma^2}{n})$部分的面积。当样本容量（$n$）增大的时候，$\frac{\sigma^2}{n}$减小，因此$\mu_1$和$\mu_2$所在分布的range都会减小，也就是说两个分布的图像都会分别以$\mu_1$和$\mu_2$为中心“变窄”。此时对于同样的<em>z score</em>代表的$k$，$P(N(\mu_2,\frac{\sigma^2}{n})&lt;k)$会减小（因为面积减小），即Type II error减小。</p><p>这就是一个对于增大本容量降低Type II error发生概率的解释。不过，用观察图像来解释原理实在是不够让人信服，连一个严谨的数学证明都没有</p><p><img src="/2018/01/24/stat/坑爹.jpg" alt=""></p><p>对于这一样本容量与Type II error发生概率的关系，是否可以通过数学公式证明呢？</p><p><img src="/2018/01/24/stat/给力.jpg" alt=""></p><p>当然可以，下面就来看看第二个更为严谨的解释。</p><h3 id="Explanation-II"><a href="#Explanation-II" class="headerlink" title="Explanation II"></a>Explanation II</h3><p>若要通过数学证明来解释样本容量与Type II error发生概率的关系，我们需引入施行特征函数：</p><p><strong>若$C$是参数$\theta$的某检验问题的一个检验法，</strong></p><p><strong><center>$\beta(\theta)=P_\theta(接受H_0)$</center></strong></p><p><strong>称为检验法$C$的施行特征函数或<em>OC</em>函数</strong></p><p>因此，当$\theta \in H_1$时，$\beta(\theta)$就是发生Type II error的概率。在这个时候$1 - \beta(\theta)$就是做出正确判断（拒绝$H_0$）的概率。函数$1 - \beta(\theta)$被称为检验法$C$的<strong>power function</strong>，在这里不深入探究。本文主要介绍通过<em>OC</em>函数来证明增大本容量可以降低Type II error的发生概率。</p><p>我们假设有$H_0: \mu &lt; \mu_0$和$H_1:\mu&gt;\mu_0$，即对$H_0$和$H_1$进行一个<em>one-sided z test</em>。对此，我们有<em>OC</em>函数</p><center>$\beta(\mu) = P_\mu(接受H_0)=P_\mu(\frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}} < z_\alpha)=P_\mu(\frac{\bar{X}-\mu}{\sigma/\sqrt{n}} < z_\alpha-\frac{\mu-\mu_0}{\sigma/\sqrt{n}})$</center><p>此处$z_\alpha$即为$\alpha$ (significance level)对应的<em>z score</em>，而由于$\frac{\bar{X}-\mu}{\sigma/\sqrt{n}} $正好是任意样本均值$\bar{X}$于正态分布$N(\mu,\frac{\sigma^2}{n})$的<em>z score</em>，可以得到</p><center>$\beta(\mu)=\phi(z_\alpha - \lambda)$</center><p>$\lambda$为$\frac{\mu-\mu_0}{\sigma/\sqrt{n}}$，而$\phi$则代表正态分布$N(\mu,\frac{\sigma^2}{n})$的<strong>分布函数（Cumulative Distribution Function, CDF）</strong>，即正态分布<strong>概率密度函数（Probability Density Function, PDF）的变上限积分</strong>。因此，我们有</p><center>$\beta(\mu) =\phi(z_\alpha - \lambda)=\frac{1} {\sqrt{2\pi}}\int_{-\infty}^{z_\alpha - \lambda}e^{-x ^{2}/2}dx$</center><p>当$\beta(\mu)$代表发生Type II error的概率时，此时正确的应是$H_1$，也就是$\mu&gt;\mu_0$，所以$\mu-\mu_0&gt;0$，增大样本容量$n$会令$\frac{\mu-\mu_0}{\sigma/\sqrt{n}}$，也即$\lambda$增大。因此$\lambda$对$n$<strong>单调递增</strong>。而当$\lambda$增大时，积分上界$z_\alpha - \lambda$随之减小，所以$\beta(\mu)$对于$\lambda$<strong>单调递减</strong>。由此可证<em>one-sided z test</em>增大样本容量可以减小Type II error发生的概率。</p><p>类似的，对于一个<em>two-sided z test</em>，若有$H_0: \mu = \mu_0$和$H_1:\mu\neq\mu_0$，我们可以求得<em>OC</em>函数</p>\begin{align}\beta(\mu) &= P_\mu(接受H_0)\\\\&= P_\mu(-z_{\alpha/2} < \frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}} < z_{\alpha/2})\\\\&=P_\mu(-\lambda-z_{\alpha/2} < \frac{\bar{X}-\mu}{\sigma/\sqrt{n}} < -\lambda+z_{\alpha/2})\\\\&=\phi(z_{\alpha/2}-\lambda)-\phi(-z_{\alpha/2}-\lambda)\end{align}<p>由正态分布图像的对称性可知$\phi(-x)=1-\phi(x)$，所以有</p><center>$\beta(\mu)=\phi(z_{\alpha/2}-\lambda)+\phi(z_{\alpha/2}+\lambda)-1$</center><p>因为此时应该选择接受$H_1$，所以$\mu\neq\mu_0$。而$z_{\alpha/2}$是一个正值，由正态分布的图像及$\lambda=\frac{\mu-\mu_0}{\sigma/\sqrt{n}}$可得当$\lambda$增大时，$\phi(z_{\alpha/2}-\lambda)$的减小的数量会大于$\phi(z_{\alpha/2}+\lambda)$增加的数量。因此，我们可以知道$\beta(\mu)$相对于$|\lambda|$<strong>单调递减</strong>。而$|\lambda|$对$n$<strong>单调递增</strong>，由此可证<em>two-sided z test</em>增大样本容量可以减小Type II error发生的概率。</p><p>此外，对于<em>t test</em>同样可以用相似的方法证明样本容量与Type II error发生概率的关系，不过推导过程更加复杂，本篇文章不作深入探讨。</p><h2 id="Mean-and-Median-in-a-Skewed-Distribution"><a href="#Mean-and-Median-in-a-Skewed-Distribution" class="headerlink" title="Mean and Median in a Skewed Distribution"></a>Mean and Median in a Skewed Distribution</h2><p>最后这个问题比较有趣，而且并不是我自己发现的。今年学统计的H同（ju）学（lao）曾问过我统计书上所写的当一个分布<em>skewed to the left</em>时，均值小于中位数，反之则均值大于中位数的原因。我当时无法回答，但确实觉得这是一个很有意思的一点，原来一直以为理所当然，从来没有深究过背后的原理。但直觉总归是不可靠的，于是我去做了一些research。</p><p>搞笑的是，“<em>skewness</em>”在历史上正是通过均值与中位数的大小关系定义的。。。</p><p><img src="/2018/01/24/stat/坑爹.jpg" alt=""></p><p>不过现代的“<em>skewness</em>”已经改用三阶中心矩来定义了。</p><p>如果各位读者想要更多了解这一点，可以去看看这一个<a href="https://www.zhihu.com/question/33636194" target="_blank" rel="noopener">知乎回答</a>，个人认为解释得还是非常好的。</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>以上就是对于AP统计中我认为的几个主要的比较有意思的问题背后的原理。</p><p>其实在学习HFI数理方面课程的时候，总是给人一种“不求甚解”的感觉，本来应该讲究数学推导，却学成了依靠背诵知识点过关的科目。下到统计，上到AC，无一例外。这对理解这一门学科所学的内容与将来的理科学习是相当不利的。尽管出于自身水平的限制，不能一一钻研自己感兴趣的所有学过而又不理解的知识点，但我始终觉得应当在学习的过程中有一种多问“为什么”的精神：起码这也能让自己学到这门科目的一点皮毛，<del>对得起这真tm贵的学费和AP考试费</del>，而不是在学完之后发现自己仅仅只是学会怎么操作一个工具而已。</p><p>希望本文能给广大挣扎在AP统计中的出国党一点帮助，也激励自己和大家对于自己真正喜欢的学科不要仅仅满足于课程考试 <del>虽然不感兴趣的学科我经常这么干（大雾）</del>，永远保持一种“好求甚解”的习惯。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>盛骤, 谢式千, 潘承毅. 概率论与数理统计, 第四版[M]. 高等教育出版社, 2008.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;去年在学习AP &lt;del&gt;TI-84/NSPIRE艺术&lt;/del&gt;统计时，总有一些骚操作让人一头雾水。而每当询问Mr. Z时，他也只是会说“This is an AP level course. You only need to know how to press the calculator.” 本篇文章讨论了几个AP统计中涵盖的公式及比较有意思的知识点背后的原理。&lt;/p&gt;
    
    </summary>
    
      <category term="Math" scheme="http://lixiuyu.cc/categories/Math/"/>
    
    
      <category term="Statistics" scheme="http://lixiuyu.cc/tags/Statistics/"/>
    
      <category term="AP" scheme="http://lixiuyu.cc/tags/AP/"/>
    
  </entry>
  
  <entry>
    <title>序-前路未知</title>
    <link href="http://lixiuyu.cc/2018/01/15/%E5%BA%8F-%E5%89%8D%E8%B7%AF%E6%9C%AA%E7%9F%A5/"/>
    <id>http://lixiuyu.cc/2018/01/15/序-前路未知/</id>
    <published>2018-01-14T17:07:01.000Z</published>
    <updated>2018-01-18T11:52:22.538Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><p>尽吾志也而不能至者，可以无悔矣 <br><br> 王安石 《游褒禅山记》</p></blockquote><p>今天是一月十二日，距离2017年已经过去了十二天。趁着记忆还算清晰，我想自己确实有必要为这特别的一年写点什么。</p><p> <img src="/2018/01/15/序-前路未知/Pit.jpeg" width="660" height="240" alt="Pittsburgh" align="center"></p><p><center><font color="#A9A9A9" size="2">8/12/2017 16:42 EST in Pittsburgh</font></center><br><a id="more"></a><br>过去一年里，我对于这个世界的认知，对于自己所想要追求的事物的思考相较以往无论在深度与广度上都不可同日而语。这或许与我从高考到留学的这一转变有关，但我想影响更大的是眼界的开阔与经历的丰富（当然进入留学圈对这两点起到了非常大的促进作用）。未来的一切仍然扑朔迷离，无论怎样试图去梳理，都感觉自己浅薄的想法触及到的都只是水中的倒影，难以捉摸。但比起在过去人生中的混沌一片，却又是好了许多。</p><p>现在回看我这一年似乎的确是过得十分充实，凭借着一股“自己选择的路，跪着也要走完”的决心与努力，最后虽然没有去成最初想去的地方，但也已经是非常好的结果了。不过认真想来自己其实本质上并没有什么长进，达成的大部分成就都有很强的功利性的目的，学不到什么真本事。更重要的是很多之前令我无比迷茫的问题仍然困扰着我，如何思考都寻找不到答案。新的困惑也接二连三的产生，更增添了我对自己未来该何去何从的不确定性。最时常伴随我的困扰主要有两个：</p><p>首要的便是时常让我倍感绝望，在理想主义与现实主义中摇摆不定的究竟该如何看待天赋的问题。这个难题贯穿着我的整个高中生涯，对我现在的方方面面都有着极为深厚的影响。在经历高一前中期的绝望与自暴自弃，后期重新意识到个人奋斗做到一定程度也可以带来巨大作用（当时看到知乎上<a href="https://www.zhihu.com/question/19555355#answer-142781" target="_blank" rel="noopener">Xiaodi Hou的回答</a>literally被震撼了，开始为了必须要做成的事适当牺牲睡眠）和心态的改变（认清天赋和出身已决定自己必然失败的事实但也要尽力冲击那一点渺茫的可能性，算是一种尽人事听天命释然吧），以及最后的来到HFI的客观推动（不再对是否出国犹豫不决从而导致无法决定努力方向），我在2017这一年实际上在尽力地避免继续深思这个问题，替换之的是先用向着短期目标的拼命努力麻木自己，试着解决紧迫的大学问题再做打算。这个方法确实大大减少了我自怨自艾与迷茫而浪费的时间，能去到Cornell似乎也代表着问题的解决：只要一直踏实地努力下去就好。</p><p>事实恰恰相反。越是顺利，我反而越发地心慌，因为自己其实心里清楚地认识到当前录取的成功只不过是一种假象。毕竟，我在学业上所取得一点小成绩并非真正的智力上的挑战，实际上任何人都可以通过一些技巧与勤奋所达到，只不过是很多人碍于风险不愿去尝试或是不想把自己搞得太累罢了。而一些稍微有点挑战性的东西我却半点都没有做到：想做的项目永远停留在构思阶段（比如某个图像识别的小东西），想完善自己的技术栈、提高编程能力却一直以弄标化GPA活动没时间的借口而原地踏步，就连想认真学点数学也是下载完pdf就从未翻开过。知乎用户<a href="https://www.zhihu.com/people/jianghanchen/activities" target="_blank" rel="noopener">@江踏歌</a>在他的专栏里写的这段话，用来描述我当前的状况真是再合适不过：</p><blockquote><p>我时常感觉到自己智力上和勇气上的缺陷。并且这两种缺陷互相将对方推入更深的泥潭中，永远走不出来，只能勉强维持自己不往下掉而已。</p><p>我虽然也非常想做原创性的工作，比如开发自己的分析工具（一系列复杂的更好的理解自然语言的topic model、并行化的算法以及炫酷的可视化工具），但这需要巨大的勇气和智力投入，使得我往往还没开头就把任务结束了。事实上，我已经开了超过100次头了。</p><p>但我又时常产生一些幻觉，认为我目前的工作仍然比那些比我层次低的人的工作水平高，而我几乎是将自己全部精力投入到维持这一虚幻的高明的工作上，并且在大部分的时间处于一种沾沾自喜的状态。</p><p>这是一场灾难。明明知道自己的工作其实非常没意思，但是没有勇气，更多的是没有智力上的自信投入到真正创新的工作中去。反而担心自己如果不维持现阶段水准的工作，就会失去更多，永远在患得患失。</p><p>我想这就是智力缺陷者，特别是那些和顶级智商的人差了一个档次的人的局限性。我们永远出不来，只能尽力维持自己工作体现出的智力水准不跌落而已。</p></blockquote><p>我当然不敢妄言自己可以和江踏歌相提并论，但尽管层次不同，心境却是相似的：这一年我虽然做了不少事，熬了许多夜，并时常为取得的成就沾沾自喜，可我做的这些东西，有多少是自己真真正正想做的有意义的事呢？论文在数学大神眼里不值一提，AP知识浅尝辄止，各类竞赛也远比不上国内比赛的难度。申上Cornell又如何？我现在的水平应该比不上任何学科竞赛的省一，更别提能进队、上清北的同学了。我与那些自己所佩服的、真正有实力的人之间的距离一丁儿点都没有减小，却愈发觉得自己更接近于所谓的“智力缺陷者”了。因此，尽管过了一年，我还是会时常诘问自己：“以你的天赋，真的可以支撑做学术的理想吗？”这个困扰，看来得等到上大学后才可能找到答案了。</p><p>第二点则是对自己所追求事物的困惑。在HFI与留学党这一圈子里见识了各种各样的人与他们所想要的各种各样的活法，感触还是挺深的。第一次发现可供自己的选择路子居然这么多，也让我开始有些迷茫到底是坚持自己的初心还是去更多地尝试其他事物。不过这个话题老生常谈，写出来想必也是索然无味，还是自己去悟吧，暂且略过不提。</p><p>总之，2017年依然是不停地怀疑自己的智商，越发感到很多人的天资、努力和取得的成就是自己可望而不可即的，时不时在浅色床单上痛哭的迷惘一年。不过确实也努力了，并幸运地取得了还算不错的成果。这一年的成长与阅历和眼界的丰富，也绝对是之前从未有能相提并论的。现在所能做的，就是不管自己天赋如何，都先别胡思乱想，而是抓住当下，正如香港的一位戴黑框眼镜的长者所言：<img src="/2018/01/15/序-前路未知/李嘉诚.png" alt=""></p><p>继续奋斗下去吧，毕竟我还年轻，热血还没有凉，仍然有足够的青春为自己的理想主义可能犯下的错挥霍。即使最后证明了自己不是学术的这块料，也能够有王文公所言的“尽吾志也而不能至者，可以无悔矣”的感觉吧。</p><hr><h3 id="写在后面"><a href="#写在后面" class="headerlink" title="写在后面"></a>写在后面</h3><p>这篇文章从十二日断断续续写到十五日（效率低下╮(￣▽￣)╭），算是我对2017年感想的一个整理，也可以作为我整个高中生涯的总结（毕竟已经是大学生了）。写作的动机呢其实挺复杂的，一直以来都有很多想法想要抒发，加上周围许多同学都开了自己的公众号，便也有意用自己拙劣的文笔来分享自己的所思所想以寻找和引发各位读者的共鸣。但又出于以往一直不善于表达自己的原因，纠结了好一段时间到底写不写这篇文。最终还是决定下笔写出来，毕竟做做总结可以更清晰地审视自己，激励与提醒自己继续不忘初心，奋斗下去。而写文章并发出去，正好也作为进入人生新的阶段一个改变，尝试一下新事物吧。</p><p>此外，由于自己未满十八岁写不了公众号TUT，爸妈也不方便提供身份证，便决定提早开放自己的博客，发在上面，作为一个开头语（本来想晚点先能够放些技术干货不显得这么寒酸再公开的，现在啥都没有_(:з」∠)_）。以后应该什么东西都会写点（学术，随笔，读书笔记 etc.），希望可以坚持下去。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;尽吾志也而不能至者，可以无悔矣 &lt;br&gt;&lt;br&gt; 王安石 《游褒禅山记》&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今天是一月十二日，距离2017年已经过去了十二天。趁着记忆还算清晰，我想自己确实有必要为这特别的一年写点什么。&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;/2018/01/15/序-前路未知/Pit.jpeg&quot; width=&quot;660&quot; height=&quot;240&quot; alt=&quot;Pittsburgh&quot; align=&quot;center&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;center&gt;&lt;font color=&quot;#A9A9A9&quot; size=&quot;2&quot;&gt;8/12/2017 16:42 EST in Pittsburgh&lt;/font&gt;&lt;/center&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="随笔" scheme="http://lixiuyu.cc/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="总结" scheme="http://lixiuyu.cc/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
</feed>
